{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to AWS Boto in Python\n",
    "\n",
    "## Chapter 1: Putting File in the Cloud!\n",
    "\n",
    "### Intro to AWS and Boto3\n",
    "\n",
    "#### What is Amazon Web Services?\n",
    "\n",
    "We buy AWS services for our projects.\n",
    "\n",
    "#### What is Boto3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3',\n",
    "                  region_name='us-east-1',\n",
    "                  aws_access_key_id=AWS_KEY_ID,\n",
    "                  aws_secret_access_key=AWS_SECRET)\n",
    "\n",
    "response = s3.list_buckets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AWS console\n",
    "* Create an account\n",
    "\n",
    "#### Creating keys with IAM\n",
    "* IAM = Identity Access Management\n",
    "* We create IAM sub-users to control access to AWS resources in our account\n",
    "* Credentials (key/secret combo) are what authenticate IAM users.\n",
    "\n",
    "#### AWS services\n",
    "* s3 or Simple Storage Service lets us store files in the cloud.\n",
    "* SNS or Simple Notification Service lets us send emails and texts.\n",
    "* Comprehend performs sentiment analysis on blocks of text.\n",
    "* Rekognition extracts text from images and looks for cats in a picture...\n",
    "\n",
    "### Diving into buckets\n",
    "\n",
    "#### S3 Components - Buckets\n",
    "* Desktop folders\n",
    "* Own permission policy\n",
    "* Website storage\n",
    "* Generate logs\n",
    "\n",
    "#### S3 Components - Objects\n",
    "* Files within the buckets (csv, jpg, etc.)\n",
    "\n",
    "#### What can we do with buckets?\n",
    "* Create Bucket\n",
    "* List Buckets\n",
    "* Delete Buckets\n",
    "\n",
    "#### Creating a Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3',\n",
    "                  region_name='us-east-1',\n",
    "                  aws_access_key_id=AWS_KEY_ID,\n",
    "                  aws_secret_access_key=AWS_SECRET)\n",
    "\n",
    "bucket = s3.create_bucket(Bucket='gid-requests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our bucket in the console\n",
    "* Bucket names need to be unique across all of s3\n",
    "\n",
    "#### Listing Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3',\n",
    "                  region_name='us-east-1',\n",
    "                  aws_access_key_id=AWS_KEY_ID,\n",
    "                  aws_secret_access_key=AWS_SECRET)\n",
    "\n",
    "bucket_response = s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = bucket_response['Buckets']\n",
    "\n",
    "for bucket in buckets:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3',\n",
    "                  region_name='us-east-1',\n",
    "                  aws_access_key_id=AWS_KEY_ID,\n",
    "                  aws_secret_access_key=AWS_SECRET)\n",
    "\n",
    "bucket = s3.delete_bucket('gid-requests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading and retrieving files\n",
    "\n",
    "#### Buckets and objects\n",
    "* An object can be anything: an image, video file, CSV or a log file\n",
    "\n",
    "#### A Bucket\n",
    "* A bucket has a **name**\n",
    "* **Name*** is a string\n",
    "* **Unique** name in all of S3.\n",
    "* Containes **many** objects\n",
    "\n",
    "#### An Object\n",
    "* An object has a **key**\n",
    "* **Name** is a full path from bucket root\n",
    "* **Unique** key in the bucket\n",
    "* Can only be in **one** parent bucket\n",
    "\n",
    "#### Creating the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3',\n",
    "                  region_name='us-east-1',\n",
    "                  aws_access_key_id=AWS_KEY_ID,\n",
    "                  aws_secret_access_key=AWS_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    Filename='gid_requests_2019_02_01.csv',\n",
    "    Bucket='gid-requests',\n",
    "    Key='gid_requests_2019_02_01.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing objects in a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3.list_objects(\n",
    "    Bucket='gid-requests',\n",
    "    MaxKeys=2,\n",
    "    Prefix='gid_requests_2019_'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting object metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3.head_object(\n",
    "    Bucket='gid-requests',\n",
    "    Key='gid_requests_2019_03_01.csv'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the size of the uploaded object\n",
    "print(response['ContentLength'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(\n",
    "    Filename='gid_requests_2019_02_01.csv',\n",
    "    Bucket='gid-requests',\n",
    "    Key='gid_requests_2019_02_01.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.delete_object(\n",
    "    Bucket='gid-requests',\n",
    "    Key='gid_requests_2019_02_01.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only objects that start with '2018/final_'\n",
    "response = s3.list_objects(Bucket='gid-staging', \n",
    "                           Prefix='2018/final_')\n",
    "print(response)\n",
    "\n",
    "# Iterate over the objects\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        # Delete the object\n",
    "        s3.delete_object(Bucket='gid-staging', Key=obj['Key'])\n",
    "\n",
    "# Print the keys of remaining objects in the bucket\n",
    "response = s3.list_objects(Bucket='gid-staging')\n",
    "\n",
    "for obj in response['Contents']:\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Sharing Files Securely\n",
    "\n",
    "### Keeping objects secure\n",
    "\n",
    "#### Why care about permissions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Gives an error\n",
    "df = pd.read_csv(\"https://git-staging.s3.amazonaws.com/potholes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AWS Permissions Systems\n",
    "* IAM\n",
    "    * Attach IAM policies to a user\n",
    "* Bucket Policy\n",
    "* ACL - Access Control Lists\n",
    "* Presigned URL\n",
    "\n",
    "#### ACLs\n",
    "* ACLs are entities attached to objects in S3\n",
    "* 2 types:\n",
    "    * private\n",
    "    * public-read\n",
    "    \n",
    "**Upload File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    Filename='potholes.csv', Bucket='gid-requests', Key='potholes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set ACL to `public-read`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.put_object_acl(\n",
    "    Bucket='gid-requests', Key='potholes.csv', ACL='public-read')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting ACLs on upload\n",
    "* Upload file with `public-read` ACL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    Bucket='gid-requests',\n",
    "    Filename='potholes.csv',\n",
    "    Key='potholes.csv',\n",
    "    ExtraArgs={'ACL':'public-read'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing public objects\n",
    "* s3 object URL Template\n",
    "`https://{bucket}}.s3.amazonaws.com/{key}`\n",
    "\n",
    "#### Generating public object URL\n",
    "* Generate Object URL String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://{}.s3.amazonaws.com/{}\".format(\n",
    "    \"gid-requests\",\n",
    "    \"2019/potholes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the URL into Pandas\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How access is decided\n",
    "* If it's a presigned URL, it will allow the download\n",
    "* If not, it will check the policies to make sure they allow the download\n",
    "\n",
    "#### Review\n",
    "* IAM: \"What can this user do in AWS?\"\n",
    "* Bucket Policy: \"Who can access this S3 bucket?\"\n",
    "* ACL: \"Who can access this object\"\n",
    "* Presigned URL: Let us grant temporary access to objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing private objects in S3\n",
    "\n",
    "#### Downloading a private file\n",
    "* Download File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(\n",
    "    Filename='potholes_local.csv',\n",
    "    Bucket='gid-staging',\n",
    "    Key='2019/potholes_private.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./potholes_local.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing private files\n",
    "* Use `.get_object()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = s3.get_object(Bucket='gid-requests', Key='2019/potholes.csv')\n",
    "\n",
    "# Response is tons of metadata\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas knows how to handle this\n",
    "pd.read_csv(obj['Body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-signed URLs\n",
    "* Expire after a certain timeframe\n",
    "* Great for temporary access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Presigned URL\n",
    "share_url = s3.generate_presigned_url(\n",
    "    ClientMethod='get_object',\n",
    "    ExpiresIn=3600,\n",
    "    Params={'Bucket': 'gid-requests', 'Key': 'potholes.csv'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open in Pandas\n",
    "pd.read_csv(share_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load multiple files into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to hold our DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Request the list of csv's from s3 with prefix; Get contents\n",
    "response = s3.list_objects(\n",
    "    Bucket='gid-requests',\n",
    "    Prefix='2019/')\n",
    "\n",
    "# Get response contents\n",
    "request_files = response['Contents']\n",
    "\n",
    "# Iterate over each object\n",
    "for file in request_files:\n",
    "    obj = s3.get_object(Bucket='gid-staging', Key=file['Key'])\n",
    "    \n",
    "    # Read it as DataFrame\n",
    "    obj_df = pd.read_csv(obj['Body'])\n",
    "    \n",
    "    # Append DataFrame to list\n",
    "    df_list.append(obj_df)\n",
    "    \n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing files through a website\n",
    "\n",
    "#### Serving HTML Pages\n",
    "\n",
    "#### HTML table in Pandas\n",
    "* Convert DataFrame to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_html('table_agg.html', \n",
    "           render_links=True,\n",
    "           columns=['service_name', 'request_count', 'info_link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_html('table_agg.html', \n",
    "           render_links=True,\n",
    "           columns=['service_name', 'request_count', 'info_link'],\n",
    "           border=0 # removes border. border=1 keeps border.\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading an HTML file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    Filename='./table_agg.html',\n",
    "    Bucket='datacamp-website',\n",
    "    Key='table.html',\n",
    "    ExtraArgs = {\n",
    "        'ContentType': 'text/html',\n",
    "        'ACL': 'public-read'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing HTML file\n",
    "* S3 object URL Template\n",
    "`https://{bucket}.s3.amazonaws.com/{key}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading other types of content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    Filename='./plot_image.png',\n",
    "    Bucket='datacamp-website',\n",
    "    Key='plot_image.png',\n",
    "    ExtraArgs = {\n",
    "        'ContentType': 'image/png'm\n",
    "        'ACL': 'public-read'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IANA Media Types\n",
    "* JSON: `application/json`\n",
    "* PNG: `image/png`\n",
    "* PDF: `application/pdf`\n",
    "* CSV: `text/csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating an index page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the gid-report bucket objects atarting with 2019/\n",
    "r = s3.list_object(Bucket='gid-reports', Prefix='2019/')\n",
    "\n",
    "# Convert the response contents to DataFrame\n",
    "objects_df = pd.DataFrame(r['Contents'])\n",
    "\n",
    "# Create a column \"Link that contains website url + key\n",
    "base_url = \"https://datacamp-website/s3/amazonaws.com/\"\n",
    "objects_df['Link'] = base_url + objects_df['Key']\n",
    "\n",
    "# Write DataFrame to html\n",
    "objects_df.to_html('report_listing.html',\n",
    "                   columns=['Link', 'LastModified', 'Size'],\n",
    "                   render_links=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading index page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    Filename='./report_listing.html',\n",
    "    Bucket='datacamp-website',\n",
    "    Key='index.html',\n",
    "    ExtraArgs = {\n",
    "        'ContentType': 'text/html',\n",
    "        'ACL': 'public-read'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study: Generating a Report Repository\n",
    "\n",
    "#### The Steps\n",
    "\n",
    "1. Prepare the data\n",
    "    * Download files for the month from the raw data bucket\n",
    "    * Concatenate them into one csv\n",
    "    * Create an aggregated DataFrame\n",
    "    \n",
    "    \n",
    "2. Create the report\n",
    "    * Write the DataFrame to CSV and HTML\n",
    "    * Generate a Bokeh plot, save as HTML\n",
    "    \n",
    "   \n",
    "3. Upload report to sharable website\n",
    "    * Create `gid-reports` bucket\n",
    "    * Upload all three files for the month to S3\n",
    "    * Generate an index.html file that lists all the files\n",
    "    \n",
    "#### Raw data bucket\n",
    "* Private files\n",
    "* Daily CSVs of requests from the App\n",
    "* Raw data\n",
    "\n",
    "#### Read raw data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to hold our DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Request the list of csv's from S3 with prefix; Get contents\n",
    "response = s3.list_objects(\n",
    "    Bucket='gid-requests',\n",
    "    Prefix='2019_jan')\n",
    "\n",
    "# Get response contents\n",
    "request_files = response['Contents']\n",
    "\n",
    "# Iterate over each object\n",
    "for file in request_files:\n",
    "    obj = s3.get_object(Bucket='gid-requests', Key=file['Key'])\n",
    "    \n",
    "    # Read it as DataFrame\n",
    "    obj_df = pd.read_csv(obj['Body'])\n",
    "    \n",
    "    # Append DataFrame to list\n",
    "    df_list.append(obj_df)\n",
    "    \n",
    "# Concatenate all the DataFrames in the list\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "# Preview the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create aggregated reports\n",
    "* Perform some aggregation\n",
    "* `df.to_csv('jan_final_report.csv')`\n",
    "* `df.to_html('jan_final_report.html')`\n",
    "* `jan_final_chart.html`\n",
    "\n",
    "#### Report bucket\n",
    "* Bucket website\n",
    "* Publicly Accessible\n",
    "* Aggregated data and HTML reports\n",
    "\n",
    "#### Upload Aggregated CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Aggregated CSV to S3\n",
    "s3.upload_file(Filename='./jan_final_report.csv',\n",
    "               Key='2019/jan/final_report.csv',\n",
    "               Bucket='gid-reports',\n",
    "               ExtraArgs = {'ACL':'public-read'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload HTML Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload HTML table to S3\n",
    "s3.upload_file(Filename='./jan_final_report.html',\n",
    "               Key='2019/jan/final_report.html',\n",
    "               Bucket='gid-reports',\n",
    "               ExtraArgs = {\n",
    "                    'ContentType':'text/html',\n",
    "                    'ACL':'public-read'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload HTML Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Aggregated Chart to S3\n",
    "s3.upload_file(Filename='./jan_final_chart.html',\n",
    "               Key='2019/jan/final_chart.html',\n",
    "               Bucket='gid-reports',\n",
    "               ExtraArgs = {\n",
    "                    'ContentType':'text/html',\n",
    "                    'ACL':'public-read'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the gid-reports bucket object starting with 2019/\n",
    "r = s3.list_objects(Bucket='gid-reports', Prefix='2019/')\n",
    "\n",
    "# Convert the response contents to DataFrame\n",
    "objects_df = pd.DataFrame(r['Contents'])\n",
    "\n",
    "# Create a column \"Link\" that contains website url + key\n",
    "base_url = 'https://gid-reports.s3.amazonaws.com/'\n",
    "objects_df['Link'] = base_url + objects_df['Key']\n",
    "\n",
    "# Write DataFrame to html\n",
    "object_df.to_html('report_listing.html',\n",
    "                  columns=['Link', 'LastModified', 'Size'],\n",
    "                  render_links=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    Filename='./report_listing.html',\n",
    "    Key='index.html',\n",
    "    Bucket='gid-reports',\n",
    "    ExtraArgs = {\n",
    "        'ContentType': 'text/html',\n",
    "        'ACL': 'public-read'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Reporting and Notifying\n",
    "\n",
    "### SNS Topics\n",
    "\n",
    "#### SNS: Simple Notification Service\n",
    "* Can send emails, push notifications, texts, etc.\n",
    "\n",
    "#### Creating an SNS Topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns = boto3.client('sns',\n",
    "                   region_name='us-east-1',\n",
    "                   aws_access_key_id=AWS_KEY_ID,\n",
    "                   aws_secret_access_key=AWS_SECRET)\n",
    "\n",
    "response = sns.create-topic(Name='city_alerts')\n",
    "\n",
    "topic_arn = response['TopicArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = response['Topics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.delete_topic(TopicArn='arn:aws:sns:us-east-1:320333787981:city_alerts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_python_toolkit",
   "language": "python",
   "name": "venv_python_toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

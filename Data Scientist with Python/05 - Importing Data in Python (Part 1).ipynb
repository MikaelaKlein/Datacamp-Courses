{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data in Python (Part 1)\n",
    "\n",
    "## Chapter 1: Flat Files\n",
    "\n",
    "#### Reading a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "filename = 'datasets/huck_finn.txt'\n",
    "file = open(filename, mode = 'r') # 'r' is to read\n",
    "text = file.read()\n",
    "file.close() # always best practice to close the cnxn to the file\n",
    "print(file.closed) # to check whether the file is closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Project Gutenberg EBook of Adventures of Huckleberry Finn, Complete\n",
      "by Mark Twain (Samuel Clemens)\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with almost\n",
      "no restrictions whatsoever. You may copy it, give it away or re-use\n",
      "it under the terms of the Project Gutenberg License included with this\n",
      "eBook or online at www.gutenberg.net\n",
      "\n",
      "Title: Adventures of Huckleberry Finn, Complete\n",
      "\n",
      "Author: Mark Twain (Samuel Clemens)\n",
      "\n",
      "Release Date: August 20, 2006 [EBook #76]\n",
      "\n",
      "Last Updated: Oc\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context manager with\n",
    "\n",
    "You can avoid having to close a connection to a file with a with statement. This allows you to create a context, that allows you to execute commands with the file open. Once out of this context, the file is no longer open, so for this reason, `with` is called a \"context manager\". What you're doing here is called binding a variable in the context manager construct. It's best practice to use the with statement as you never have to concern yourself with closing the file again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Project Gutenberg EBook of Adventures of Huckleberry Finn, Complete\n",
      "by Mark Twain (Samuel Clemens)\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with almost\n",
      "no restrictions whatsoever. You may copy it, give it away or re-use\n",
      "it under the terms of the Project Gutenberg License included with this\n",
      "eBook or online at www.gutenberg.net\n",
      "\n",
      "Title: Adventures of Huckleberry Finn, Complete\n",
      "\n",
      "Author: Mark Twain (Samuel Clemens)\n",
      "\n",
      "Release Date: August 20, 2006 [EBook #76]\n",
      "\n",
      "Last Updated: Oc\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/huck_finn.txt', 'r') as file:\n",
    "    print(file.read()[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only want to print a few lines of the text file, the `readline()` method allows you to do that. You can print out the first line by executing `file.readline()` and if you execute that again, it will print the second line, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "The Project Gutenberg EBook of Adventures of Huckleberry Finn, Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/huck_finn.txt') as file:\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat files\n",
    "\n",
    "Flat files are basic text files containing records, that is, table data, without structured relationships. Flat files can have headers. Common types of flat files are .csv, .txt.\n",
    "\n",
    "#### Why NumPy?\n",
    "* NumPy arrays: standard for storing numerical data\n",
    "* Essential for other packages: e.g. scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [2., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "filename = 'datasets/NMIST.txt'\n",
    "data = np.loadtxt(filename, delimiter = ',') # default delimiter is a space\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 0.],\n",
       "       [4., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if your data contains a header, you'll want to skip the first row\n",
    "# you can also specifcy which columns you want\n",
    "data = np.loadtxt(filename, delimiter = ',', skiprows = 1, usecols = [0, 2])\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1.0', '0.0', '0.0', ..., '0.0', '0.0', '0.0'],\n",
       "       ['0.0', '0.0', '0.0', ..., '0.0', '0.0', '0.0'],\n",
       "       ['1.0', '0.0', '0.0', ..., '0.0', '0.0', '0.0'],\n",
       "       ...,\n",
       "       ['2.0', '0.0', '0.0', ..., '0.0', '0.0', '0.0'],\n",
       "       ['0.0', '0.0', '0.0', ..., '0.0', '0.0', '0.0'],\n",
       "       ['5.0', '0.0', '0.0', ..., '0.0', '0.0', '0.0']], dtype='<U5')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also make the entire import a string\n",
    "data = np.loadtxt(filename, delimiter = ',', dtype = str)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have data of different data types, but still want to creat a numpy array you can use `np.genfromtxt()`. Because the data are of different types, data is an object called a structured array. Because numpy arrays have to contain elements that are all the same type, the structured array solves this by being a 1D array, where each element of the array is a row of the flat file imported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MikaelaKlein/.venvs/venv_python_toolkit/lib/python3.6/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([(1, 0, 3, b'male', 22., 1, 0, b'A/5 21171',  7.25  , b'', b'S'),\n",
       "       (2, 1, 1, b'female', 38., 1, 0, b'PC 17599', 71.2833, b'C85', b'C'),\n",
       "       (3, 1, 3, b'female', 26., 0, 0, b'STON/O2. 3101282',  7.925 , b'', b'S'),\n",
       "       (4, 1, 1, b'female', 35., 1, 0, b'113803', 53.1   , b'C123', b'S'),\n",
       "       (5, 0, 3, b'male', 35., 0, 0, b'373450',  8.05  , b'', b'S')],\n",
       "      dtype=[('PassengerId', '<i8'), ('Survived', '<i8'), ('Pclass', '<i8'), ('Sex', 'S6'), ('Age', '<f8'), ('SibSp', '<i8'), ('Parch', '<i8'), ('Ticket', 'S18'), ('Fare', '<f8'), ('Cabin', 'S15'), ('Embarked', 'S1')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('datasets/titanic.csv', delimiter=',', names=True, dtype=None)\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also another function `np.recfromcsv()` that behaves similarly to `np.genfromtxt()`, except that its default dtype is `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0, 3, b'male', 22., 1, 0, b'A/5 21171',  7.25  , b'', b'S')\n",
      " (2, 1, 1, b'female', 38., 1, 0, b'PC 17599', 71.2833, b'C85', b'C')\n",
      " (3, 1, 3, b'female', 26., 0, 0, b'STON/O2. 3101282',  7.925 , b'', b'S')]\n"
     ]
    }
   ],
   "source": [
    "# Assign the filename: file\n",
    "file = 'datasets/titanic.csv'\n",
    "\n",
    "# Import file using np.recfromcsv: d\n",
    "d = np.recfromcsv(file)\n",
    "\n",
    "# Print out first three entries of d\n",
    "print(d[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What a data scientist needs\n",
    "* Two-dimensional labeled data structure(s)\n",
    "* Columns of potentially different types\n",
    "* Manipulate, slice, reshape, groupby, join, merge\n",
    "* Perform statistics\n",
    "* Work with time series data\n",
    "\n",
    "#### Manipulating pandas DataFrames\n",
    "* Exploratory data analysis\n",
    "* Data wrangling\n",
    "* Data preprocessing\n",
    "* Building models\n",
    "* Visualization\n",
    "* Standard and best practice to use pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = 'datasets/winequality-red.csv'\n",
    "data = pd.read_csv(filename, sep = \";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.400e+00, 7.000e-01, 0.000e+00, 1.900e+00, 7.600e-02, 1.100e+01,\n",
       "        3.400e+01, 9.978e-01, 3.510e+00, 5.600e-01, 9.400e+00, 5.000e+00],\n",
       "       [7.800e+00, 8.800e-01, 0.000e+00, 2.600e+00, 9.800e-02, 2.500e+01,\n",
       "        6.700e+01, 9.968e-01, 3.200e+00, 6.800e-01, 9.800e+00, 5.000e+00],\n",
       "       [7.800e+00, 7.600e-01, 4.000e-02, 2.300e+00, 9.200e-02, 1.500e+01,\n",
       "        5.400e+01, 9.970e-01, 3.260e+00, 6.500e-01, 9.800e+00, 5.000e+00],\n",
       "       [1.120e+01, 2.800e-01, 5.600e-01, 1.900e+00, 7.500e-02, 1.700e+01,\n",
       "        6.000e+01, 9.980e-01, 3.160e+00, 5.800e-01, 9.800e+00, 6.000e+00],\n",
       "       [7.400e+00, 7.000e-01, 0.000e+00, 1.900e+00, 7.600e-02, 1.100e+01,\n",
       "        3.400e+01, 9.978e-01, 3.510e+00, 5.600e-01, 9.400e+00, 5.000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also easily convert the dataframe to a numpy array by calling\n",
    "data.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Importing data from other file types\n",
    "\n",
    "### Other file types\n",
    "\n",
    "* Excel spreadsheets\n",
    "* MATLAB files\n",
    "* SAS\n",
    "* Stata files\n",
    "* HDF5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickled files\n",
    "* Files type native to Python\n",
    "* Motivation: many datatypes for which it isn't obvious how to store them\n",
    "* Pickled files are serialized\n",
    "* Serialize = convert object to bytestream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# specify that the file is read-only and binary by using 'rb'\n",
    "with open('pickled_fruit.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Excel spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2002', '2004']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = 'datasets/battledeath.xlsx'\n",
    "data = pd.ExcelFile(file)\n",
    "print(data.sheet_names)\n",
    "# df1 = data.parse('sheet_name1')\n",
    "df1 = data.parse(0) # sheet index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAS and Stata files\n",
    "* SAS: Statistical Analysis System\n",
    "    * business analytics and biostatistics\n",
    "    * Used for:\n",
    "        * Advanced analytics\n",
    "        * Multivariate analysis\n",
    "        * Business intelligence\n",
    "        * Data management\n",
    "        * Predictive analytics\n",
    "    * Standard for computational analysis\n",
    "    * The most common SAS files have the exention .sas7bdat and .sas7bcat which are dataset files and catalog files respectively. We can import the former shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>P</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>181.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>245.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>250.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>265.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>248.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR     P           S\n",
       "0  1950.0  12.9  181.899994\n",
       "1  1951.0  11.9  245.000000\n",
       "2  1952.0  10.7  250.199997\n",
       "3  1953.0  11.3  265.899994\n",
       "4  1954.0  11.2  248.500000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "with SAS7BDAT('datasets/sales.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "    \n",
    "df_sas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "* Stata: \"Statistics\" + \"data\n",
    "    * academic social sciences research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wbcode</th>\n",
       "      <th>country</th>\n",
       "      <th>disa1</th>\n",
       "      <th>disa2</th>\n",
       "      <th>disa3</th>\n",
       "      <th>disa4</th>\n",
       "      <th>disa5</th>\n",
       "      <th>disa6</th>\n",
       "      <th>disa7</th>\n",
       "      <th>disa8</th>\n",
       "      <th>...</th>\n",
       "      <th>disa16</th>\n",
       "      <th>disa17</th>\n",
       "      <th>disa18</th>\n",
       "      <th>disa19</th>\n",
       "      <th>disa20</th>\n",
       "      <th>disa21</th>\n",
       "      <th>disa22</th>\n",
       "      <th>disa23</th>\n",
       "      <th>disa24</th>\n",
       "      <th>disa25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  wbcode               country  disa1  disa2  disa3  disa4  disa5  disa6  \\\n",
       "0    AFG           Afghanistan   0.00   0.00   0.76   0.73    0.0   0.00   \n",
       "1    AGO                Angola   0.32   0.02   0.56   0.00    0.0   0.00   \n",
       "2    ALB               Albania   0.00   0.00   0.02   0.00    0.0   0.00   \n",
       "3    ARE  United Arab Emirates   0.00   0.00   0.00   0.00    0.0   0.00   \n",
       "4    ARG             Argentina   0.00   0.24   0.24   0.00    0.0   0.23   \n",
       "\n",
       "   disa7  disa8  ...  disa16  disa17  disa18  disa19  disa20  disa21  disa22  \\\n",
       "0   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "1   0.56    0.0  ...     0.0     0.4     0.0    0.61    0.00     0.0    0.99   \n",
       "2   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "3   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "4   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.05     0.0    0.00   \n",
       "\n",
       "   disa23  disa24  disa25  \n",
       "0    0.02    0.00    0.00  \n",
       "1    0.98    0.61    0.00  \n",
       "2    0.00    0.00    0.16  \n",
       "3    0.00    0.00    0.00  \n",
       "4    0.01    0.00    0.11  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_stata('datasets/disarea.dta')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDF5 files\n",
    "* Hierarchical Data Format version 5\n",
    "* Standard for storing large quantities of numerical data\n",
    "* Datasets can be hundreds of gigabytes or terabytes\n",
    "* HDF5 can scale to exabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.files.File'>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "filename = 'datasets/LIGO.hdf5'\n",
    "data = h5py.File(filename, 'r') # 'r' is to read\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta\n",
      "quality\n",
      "strain\n"
     ]
    }
   ],
   "source": [
    "for key in data.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description\n",
      "DescriptionURL\n",
      "Detector\n",
      "Duration\n",
      "GPSstart\n",
      "Observatory\n",
      "Type\n",
      "UTCstart\n"
     ]
    }
   ],
   "source": [
    "for key in data['meta'].keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Strain data time series from LIGO' b'L1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MikaelaKlein/.venvs/venv_python_toolkit/lib/python3.6/site-packages/ipykernel_launcher.py:1: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(data['meta']['Description'].value, data['meta']['Detector'].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MATLAB\n",
    "* \"Matrix Laboratory\"\n",
    "* Industry standard in engineering and science\n",
    "* Saved as .mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "filename = 'workspace.mat'\n",
    "mat = scipy.io.loadmat(filename)\n",
    "print(type(mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Introduction to Relational Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relational Database Management Systems\n",
    "* PostgreSQL\n",
    "* MySQL\n",
    "* SQLite\n",
    "* SQL = Structured Query Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a database engine\n",
    "* SQLite database\n",
    "    * Fast and simple\n",
    "    \n",
    "* SQLAlchemy\n",
    "    * Works with many Relational Database Management Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# insert type of database and name of the database\n",
    "engine = create_engine('sqlite::///datasets/Chinook.sqlite')\n",
    "\n",
    "table_names = engine.table_names()\n",
    "\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = engine.connect()\n",
    "\n",
    "rs = con.execute(\"SELECT * FROM ORDERS\")\n",
    "\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "df.columns = rs.keys()\n",
    "\n",
    "con.close()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT OrderID, OrderDate, ShipName FROM Orders\")\n",
    "    df = pd.DataFrame(rs.fetchmany(size=5))\n",
    "    df.columns = rs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The pandas way to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM Orders\", engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_python_toolkit",
   "language": "python",
   "name": "venv_python_toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
